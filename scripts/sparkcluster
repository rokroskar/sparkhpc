#!/bin/env python
#
#
# CLI for starting and running Spark standalone clusters on HPC resources
#
#

from __future__ import print_function
import click
import sparkhpc
from sparkhpc import sparkjob
import subprocess
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('sparkhpc')

home = os.path.expanduser('~')

SCHEDULER = sparkjob.get_scheduler()

@click.group()
@click.option('--scheduler', type=click.Choice(['lsf', 'slurm']), default=SCHEDULER, help='Which scheduler to use')
@click.pass_context
def cli(ctx, scheduler):
    ctx.obj['SJ'] = sparkjob.sparkjob


@cli.command()
@click.argument('ncores', type=int)
@click.option('--walltime', default="00:30", help="Walltime in HH:MM format")
@click.option('--jobname', default='sparkcluster', help='Name to use for the job')
@click.option('--template', default=None, help='Job template path')
@click.option('--memory', default='2000', envvar='SPARK_WORKER_MEMORY',
              help='Memory for each worker in MB')
@click.option('--spark-home', default=os.path.join(home,'spark'), envvar='SPARK_HOME', 
              help='Location of the Spark distribution')
@click.option('--wait', default=False, is_flag=True, help='Wait until the job starts')
@click.pass_context
def start(ctx, ncores, walltime, jobname, template, memory, spark_home, wait):
    """Start the spark cluster as a batch job"""
    
    SJ = ctx.obj['SJ']

    sj = SJ(ncores=ncores, walltime=walltime, jobname=jobname, template=template, memory=memory, spark_home=spark_home)
    
    if wait: 
        logger.info(' Waiting for job to start - ctrl-c to stop')
        sj.wait_to_start()
    else:
        sj.submit()
    

@cli.command()
@click.pass_context
def info(ctx):
    """Get info about currently running clusters"""
    # SJ = ctx.obj['SJ']
    # sjs = SJ.current_clusters()

    # if len(sjs)>0:
    #     sjs[0].show_clusters()
    # else: 
    #     logger.info(' No spark clusters running')
    sparkhpc.show_clusters()

@cli.command()
@click.argument('clusterid')
@click.pass_context
def stop(ctx, clusterid):
    """Kill a currently running cluster ('all' to kill all clusters)"""
    SJ = ctx.obj['SJ']
    sjs = SJ.current_clusters()

    if clusterid == 'all': 
        if len(sjs) == 0: 
            logger.info(' No clusters running')
        for sj in sjs: 
            sj.stop()
    elif int(clusterid) < len(sjs): 
        sjs[int(clusterid)].stop()
    else: 
        raise RuntimeError('Cluster %s does not exist'%clusterid)


@cli.command()
@click.option('--memory', default='2000M', help='Memory for each worker in MB')
@click.option('--timeout', default=30, help='Timeout for starting spark master')
@click.option('--cores-per-executor', default=1, help='Number of cores per executor')
@click.pass_context
def launch(ctx, memory, timeout, cores_per_executor):
    """Launch the Spark master and workers within a current job context"""
    sparkjob.start_cluster(memory, timeout=timeout, cores_per_executor=cores_per_executor)

if __name__ == "__main__":
    cli(obj={})
